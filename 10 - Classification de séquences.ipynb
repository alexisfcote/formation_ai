{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de noms en utilisant un RNN\n",
    "\n",
    "Dans ce tutorie nous introduisont les réseaux de neurones récurrents (RNNs).\n",
    "\n",
    "Pour cet fin, nous travaillerons sur la classification de noms qui peuvent être soient une compagnie ou une personne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 3\n",
    "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "n_epoch = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La taille du jeu de données ici est très petite et sert seulement à démontrer le concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names_manual_annotation.tsv') as f:\n",
    "    data = f.readlines()\n",
    "    data = [d[:-1].split('\\t') for d in data]\n",
    "data = [(x, y) for x, y in data if y != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Québec (Ville de)', 'Company'),\n",
       " ('Drouin', 'Person'),\n",
       " ('Pneus Métro inc.', 'Company'),\n",
       " ('Graton', 'Person'),\n",
       " ('English', 'Person'),\n",
       " ('Clinique vétérinaire Ève Woods-Lavoie inc.', 'Company'),\n",
       " ('Grimard', 'Person'),\n",
       " ('St-Amand', 'Person'),\n",
       " ('Douville', 'Person'),\n",
       " ('Fréchette', 'Person')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous allons travailler lettre par lettre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_examples(data):\n",
    "    examples = list()\n",
    "    for name, tag in data:\n",
    "        examples.append((list(name), tag))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['D', 'r', 'o', 'u', 'i', 'n'], 'Person')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data = format_examples(data)\n",
    "formatted_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data = random.sample(formatted_data, len(formatted_data))\n",
    "train_ratio = int(len(formatted_data)*0.8) # 80% of dataset\n",
    "train = formatted_data[:train_ratio]\n",
    "test = formatted_data[train_ratio:]\n",
    "valid_ratio = int(len(train)*0.8) # 20% of train set\n",
    "valid = train[valid_ratio:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 127, 159)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons nous créer un vocabulaire pour toute donnée \"non numérique\". Ce vocabulaire nous sert d'index qui sera utilisé pour trouvé le vecteur de rééls associé à cet élément non numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "tags = set()\n",
    "\n",
    "for example in train:\n",
    "    for char in example[0]:\n",
    "        vocab.add(char)\n",
    "    tags.add(example[1])\n",
    "    \n",
    "char_to_idx = {\n",
    "    '<PAD>': 0,\n",
    "    '<UNK>': 1,\n",
    "}\n",
    "\n",
    "for char in sorted(vocab):\n",
    "    char_to_idx[char] = len(char_to_idx)\n",
    "    \n",
    "tag_to_idx = {tag: i for i, tag in enumerate(sorted(tags))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " ' ': 2,\n",
       " '&': 3,\n",
       " \"'\": 4,\n",
       " '(': 5,\n",
       " ')': 6,\n",
       " ',': 7,\n",
       " '-': 8,\n",
       " '.': 9,\n",
       " '/': 10,\n",
       " '0': 11,\n",
       " '1': 12,\n",
       " '2': 13,\n",
       " '3': 14,\n",
       " '4': 15,\n",
       " '5': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " 'A': 21,\n",
       " 'B': 22,\n",
       " 'C': 23,\n",
       " 'D': 24,\n",
       " 'E': 25,\n",
       " 'F': 26,\n",
       " 'G': 27,\n",
       " 'H': 28,\n",
       " 'I': 29,\n",
       " 'J': 30,\n",
       " 'K': 31,\n",
       " 'L': 32,\n",
       " 'M': 33,\n",
       " 'N': 34,\n",
       " 'O': 35,\n",
       " 'P': 36,\n",
       " 'Q': 37,\n",
       " 'R': 38,\n",
       " 'S': 39,\n",
       " 'T': 40,\n",
       " 'U': 41,\n",
       " 'V': 42,\n",
       " 'W': 43,\n",
       " 'X': 44,\n",
       " 'Y': 45,\n",
       " 'Z': 46,\n",
       " 'a': 47,\n",
       " 'b': 48,\n",
       " 'c': 49,\n",
       " 'd': 50,\n",
       " 'e': 51,\n",
       " 'f': 52,\n",
       " 'g': 53,\n",
       " 'h': 54,\n",
       " 'i': 55,\n",
       " 'j': 56,\n",
       " 'k': 57,\n",
       " 'l': 58,\n",
       " 'm': 59,\n",
       " 'n': 60,\n",
       " 'o': 61,\n",
       " 'p': 62,\n",
       " 'q': 63,\n",
       " 'r': 64,\n",
       " 's': 65,\n",
       " 't': 66,\n",
       " 'u': 67,\n",
       " 'v': 68,\n",
       " 'w': 69,\n",
       " 'x': 70,\n",
       " 'y': 71,\n",
       " 'z': 72,\n",
       " 'É': 73,\n",
       " 'â': 74,\n",
       " 'ç': 75,\n",
       " 'è': 76,\n",
       " 'é': 77,\n",
       " 'ê': 78,\n",
       " 'ë': 79,\n",
       " 'î': 80,\n",
       " 'ô': 81,\n",
       " '—': 82}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Company': 0, 'Person': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Vectorizer va nous servir à convertir toute donnée 'non numérique' en donnée numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    def __init__(self, char_to_idx, tag_to_idx):\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "\n",
    "    def vectorize_sequence(self, sequence, idx, remove_if_unk=False):\n",
    "        if '<UNK>' in idx:\n",
    "            unknown_index = idx['<UNK>']\n",
    "            chars = [idx.get(tok, unknown_index) for tok in sequence]\n",
    "            if remove_if_unk:\n",
    "                return [w for w in chars if w != unknown_index]\n",
    "            else:\n",
    "                return chars\n",
    "\n",
    "        else:\n",
    "            return [idx[tok] for tok in sequence]\n",
    "\n",
    "    def __call__(self, example):\n",
    "        name, tag = example\n",
    "        vectorized_name = self.vectorize_sequence(name, self.char_to_idx)\n",
    "        vectorized_tag = self.tag_to_idx[tag]\n",
    "        return (\n",
    "            vectorized_name,\n",
    "            vectorized_tag,\n",
    "        )\n",
    "\n",
    "vectorizer = Vectorizer(char_to_idx, tag_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [vectorizer(example) for example in train]\n",
    "valid_data = [vectorizer(example) for example in valid]\n",
    "test_data = [vectorizer(example) for example in test]\n",
    "\n",
    "datasets = {'train':train_data, 'val':valid_data, 'test':test_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([32, 47, 62, 61, 55, 60, 66, 51], 1),\n",
       " (['L', 'a', 'p', 'o', 'i', 'n', 't', 'e'], 'Person'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le concept de padding est extrêmement important. Il nous permet d'envoyer des tenseurs de longueurs différentes sur le GPU.\n",
    "\n",
    "Nous prenons donc le tenseur le plus long de notre minibatch pour créer une matrice d'exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pad_sequences(vectorized_seqs, seq_lengths):\n",
    "    seq_tensor = torch.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
    "    for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq[:seqlen])\n",
    "    return seq_tensor\n",
    "\n",
    "def collate_examples(samples):\n",
    "    names, tags = list(zip(*samples))\n",
    "    names_lengths = torch.LongTensor([len(s) for s in names])\n",
    "    padded_names = pad_sequences(names, names_lengths)\n",
    "    tags = torch.LongTensor(tags)\n",
    "    return padded_names, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_examples,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_examples,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_examples,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 48]),\n",
       " (tensor([[39, 55, 60, 53, 58, 51, 66, 61, 60,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [38, 55, 61, 67, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [38, 51, 65, 66, 47, 67, 64, 47, 60, 66,  8, 22, 47, 64,  2, 32, 47,  2,\n",
       "           38, 61, 49, 54, 51, 58, 55, 76, 64, 51,  2, 55, 60, 49,  9,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [25, 70, 49, 47, 68, 47, 66, 55, 61, 60, 65,  2, 27,  9,  2, 21, 58, 58,\n",
       "           47, 64, 50,  2, 55, 60, 49,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [20, 13, 13, 11,  8, 17, 17, 15, 19,  2, 37, 67, 77, 48, 51, 49,  2, 55,\n",
       "           60, 49,  9,  2,  5, 23, 61, 60, 65, 66, 64, 67, 49, 66, 55, 61, 60,  2,\n",
       "           40, 51, 49, 54, 60, 55,  8, 62, 58, 67, 65,  6],\n",
       "          [30, 61, 58, 55,  8, 23, 61, 51, 67, 64,  2, 32, 47, 49, 47, 65, 65, 51,\n",
       "            7,  2, 65,  9, 51,  9, 60,  9, 49,  9, 64,  9, 58,  9,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [23, 77, 49, 55, 58,  2, 22, 55, 58, 61, 50, 51, 47, 67,  2, 21, 67, 66,\n",
       "           61, 65,  2, 58, 66, 77, 51,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [39, 47, 62, 55, 60, 55, 76, 64, 51,  2, 39, 66,  8, 28, 61,  7,  2, 65,\n",
       "            9, 51,  9, 60,  9, 49,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [25, 52, 64, 51, 59, 55, 47, 60,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [24, 51, 65, 49, 61, 66, 51, 47, 67, 70,  2,  5, 23, 61, 60, 65, 66, 64,\n",
       "           67, 49, 66, 55, 61, 60,  2, 33,  9,  2, 24, 51, 65, 49, 61, 66, 51, 47,\n",
       "           67, 70,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [39, 61, 67, 49, 71,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [26, 64, 47, 50, 51, 66, 66, 51,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [40, 47, 58, 48, 61, 66,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [22, 55, 65, 59, 47, 64,  2, 55, 60, 49,  9,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [73, 48, 77, 60, 55, 65, 66, 51, 64, 55, 51,  2, 30,  9, 23,  9,  2, 36,\n",
       "           55, 49, 47, 64, 50,  2, 55, 60, 49,  9,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "          [27, 55, 47, 64, 50,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(train_loader))\n",
    "b[0].shape, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "class NameClassifier(nn.Module):\n",
    "    def __init__(self, char_to_idx, tag_to_idx, embedding_size, hidden_layer_size):\n",
    "        super(NameClassifier, self).__init__()\n",
    "        self.embeddings = nn.Embedding(len(char_to_idx), embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_layer_size)\n",
    "        self.fully_connected = nn.Linear(hidden_layer_size, len(tag_to_idx))\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.metrics = ['acc']\n",
    "\n",
    "    def forward(self, names):\n",
    "        # Getting the length of sequences so we can pack them and send them to gpu.\n",
    "        # We also sort the sequences by length, as required by the pack_padded_sequence function\n",
    "        seq_lengths, perm_idx = (names > 0).sum(dim=1).sort(0, descending=True)\n",
    "        \n",
    "        # We need the reverse idx to unsort the sequence at the end of the forward\n",
    "        _, rev_perm_idx = perm_idx.sort(0)\n",
    "        \n",
    "        # (batch_size, max_length)\n",
    "        sorted_names = names[perm_idx]\n",
    "        \n",
    "        # (batch_size, max_length, embedding_size)\n",
    "        embeds = self.embeddings(sorted_names)\n",
    "        \n",
    "        packed_names = pack_padded_sequence(embeds, seq_lengths, batch_first=True)\n",
    "        \n",
    "        # (1, batch_size, hidden_layer_size)\n",
    "        _, (h_n, _) = self.rnn(packed_names)\n",
    "        \n",
    "        # (1, batch_size, num_tags)\n",
    "        out = self.fully_connected(h_n)\n",
    "        \n",
    "        # (batch_size, num_tags)\n",
    "        out = out.squeeze(0)\n",
    "        \n",
    "        return out[rev_perm_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train':train_loader, 'val':valid_loader, 'test':test_loader}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NameClassifier(char_to_idx, tag_to_idx, embedding_size=50, hidden_layer_size=100)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.5859 Acc: 0.7587\n",
      "val Loss: 0.4102 Acc: 0.9134\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.3497 Acc: 0.9069\n",
      "val Loss: 0.2655 Acc: 0.9370\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2755 Acc: 0.9132\n",
      "val Loss: 0.2310 Acc: 0.9449\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2547 Acc: 0.9180\n",
      "val Loss: 0.2126 Acc: 0.9449\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2445 Acc: 0.9211\n",
      "val Loss: 0.2054 Acc: 0.9449\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2357 Acc: 0.9211\n",
      "val Loss: 0.1978 Acc: 0.9449\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2281 Acc: 0.9243\n",
      "val Loss: 0.1868 Acc: 0.9449\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2170 Acc: 0.9243\n",
      "val Loss: 0.1857 Acc: 0.9449\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2081 Acc: 0.9290\n",
      "val Loss: 0.1741 Acc: 0.9528\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1974 Acc: 0.9306\n",
      "val Loss: 0.1633 Acc: 0.9528\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1822 Acc: 0.9385\n",
      "val Loss: 0.1337 Acc: 0.9528\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1519 Acc: 0.9479\n",
      "val Loss: 0.0889 Acc: 0.9843\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0949 Acc: 0.9669\n",
      "val Loss: 0.0405 Acc: 1.0000\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0657 Acc: 0.9779\n",
      "val Loss: 0.0206 Acc: 1.0000\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0409 Acc: 0.9890\n",
      "val Loss: 0.0178 Acc: 1.0000\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0355 Acc: 0.9890\n",
      "val Loss: 0.0077 Acc: 1.0000\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.9905\n",
      "val Loss: 0.0178 Acc: 1.0000\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0287 Acc: 0.9874\n",
      "val Loss: 0.0060 Acc: 1.0000\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0177 Acc: 0.9953\n",
      "val Loss: 0.0051 Acc: 1.0000\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0216 Acc: 0.9905\n",
      "val Loss: 0.0041 Acc: 1.0000\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0415 Acc: 0.9858\n",
      "val Loss: 0.0155 Acc: 1.0000\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 0.9921\n",
      "val Loss: 0.0103 Acc: 1.0000\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0143 Acc: 0.9968\n",
      "val Loss: 0.0036 Acc: 1.0000\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0135 Acc: 0.9953\n",
      "val Loss: 0.0032 Acc: 1.0000\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0095 Acc: 0.9984\n",
      "val Loss: 0.0030 Acc: 1.0000\n",
      "\n",
      "Training complete in 0m 9s\n",
      "Best val Acc: 1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NameClassifier(\n",
       "  (embeddings): Embedding(83, 50)\n",
       "  (rnn): LSTM(50, 100)\n",
       "  (fully_connected): Linear(in_features=100, out_features=2, bias=True)\n",
       "  (loss_function): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 1, gamma=1) # no scheduling\n",
    "train_model(net, loss_function, optimizer, scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Frégeau', 'Person', 'Person'),\n",
       " ('Wesler', 'Person', 'Person'),\n",
       " ('Bordeleau', 'Person', 'Person'),\n",
       " ('Fils Transport inc.', 'Company', 'Company'),\n",
       " ('Tremblay', 'Person', 'Person'),\n",
       " ('Bérubé', 'Person', 'Person'),\n",
       " ('9308-5934 Québec inc. (Volvo Trois-Rivières)', 'Company', 'Company'),\n",
       " ('Comptois', 'Person', 'Person'),\n",
       " ('Khan', 'Person', 'Person'),\n",
       " ('DIM Stone inc.', 'Company', 'Company'),\n",
       " ('Mazda Canada inc.', 'Company', 'Company'),\n",
       " ('Ferme Les 2B inc.', 'Company', 'Company'),\n",
       " ('Martineau', 'Person', 'Person'),\n",
       " ('Parent (Maison de rêve PGV)', 'Company', 'Company'),\n",
       " ('Javid', 'Person', 'Person'),\n",
       " ('Verhoef', 'Person', 'Person'),\n",
       " ('Moore', 'Person', 'Person'),\n",
       " ('Clinique vétérinaire <UNK>ve Woods-Lavoie inc.', 'Company', 'Company'),\n",
       " ('Dubé', 'Person', 'Person'),\n",
       " ('Gheys Allah', 'Person', 'Person'),\n",
       " ('Brochu', 'Person', 'Person'),\n",
       " ('CHUM Hôpital Notre-Dame', 'Company', 'Company'),\n",
       " ('Nathan (Custom Rides)', 'Company', 'Company'),\n",
       " ('Giasson', 'Person', 'Person'),\n",
       " ('Potvin pneus mécanique', 'Company', 'Company'),\n",
       " ('Indemnipro', 'Company', 'Company'),\n",
       " ('Bun', 'Person', 'Person'),\n",
       " ('Paris', 'Person', 'Person'),\n",
       " ('Condos Résidence Le Laurier inc.', 'Company', 'Company'),\n",
       " ('Brais', 'Person', 'Person'),\n",
       " ('Joseph Élie ltée', 'Company', 'Company'),\n",
       " ('Van Diepen', 'Company', 'Person'),\n",
       " ('St-Amand Corneli', 'Company', 'Person'),\n",
       " ('Hétu', 'Person', 'Person'),\n",
       " ('Coursol', 'Person', 'Person'),\n",
       " ('Léonard', 'Person', 'Person'),\n",
       " ('Lajoie', 'Person', 'Person'),\n",
       " ('Toth', 'Person', 'Person'),\n",
       " ('Desjardins Assurances générales inc.', 'Company', 'Company'),\n",
       " ('9219-2640 Québec inc.', 'Company', 'Company'),\n",
       " ('Diamant Transport logistiques inc.', 'Company', 'Company'),\n",
       " ('Re/Max Future inc.', 'Company', 'Company'),\n",
       " ('Bergeron Électrique inc.', 'Company', 'Company'),\n",
       " ('Hubert', 'Person', 'Person'),\n",
       " ('Parent', 'Person', 'Person'),\n",
       " ('Gravel', 'Person', 'Person'),\n",
       " ('Quessy', 'Person', 'Person'),\n",
       " ('Groupe Le Massif inc.', 'Company', 'Company'),\n",
       " ('Estiverne', 'Person', 'Person'),\n",
       " ('Loksairy', 'Person', 'Person'),\n",
       " ('Landreville', 'Person', 'Person'),\n",
       " ('Desroches', 'Person', 'Person'),\n",
       " ('Bayart', 'Person', 'Person'),\n",
       " ('Coteau-du-Lac (Ville de)', 'Company', 'Company'),\n",
       " ('Hassan', 'Person', 'Person'),\n",
       " ('Métamorphose Santé inc.', 'Company', 'Company'),\n",
       " ('St-Onge', 'Person', 'Person'),\n",
       " ('Groupe concept PV inc.', 'Company', 'Company'),\n",
       " ('Contruction et rénovation Michel Lemay inc.', 'Company', 'Company'),\n",
       " ('Songo', 'Person', 'Person'),\n",
       " ('Les Emballages Esquire Packaging Canada inc.', 'Company', 'Company'),\n",
       " ('Bellefeuille', 'Person', 'Person'),\n",
       " ('Aubé', 'Person', 'Person'),\n",
       " ('Bellavance', 'Person', 'Person'),\n",
       " ('Entreprises électriques Michel Poissant inc.', 'Company', 'Company'),\n",
       " ('Comet', 'Person', 'Person'),\n",
       " ('Déneigements JPR inc.', 'Company', 'Company'),\n",
       " ('Modéry', 'Person', 'Person'),\n",
       " ('Aliane', 'Person', 'Person'),\n",
       " ('Guignard', 'Person', 'Person'),\n",
       " ('Wu', 'Person', 'Person'),\n",
       " ('Caravane Horizon inc. (A.S. Lévesque Trois-Rivières)',\n",
       "  'Company',\n",
       "  'Company'),\n",
       " ('Trépanier', 'Person', 'Person'),\n",
       " ('Kubba', 'Person', 'Person'),\n",
       " ('Lauzon', 'Person', 'Person'),\n",
       " ('Gestion MSGM', 'Person', 'Company'),\n",
       " ('Douville', 'Person', 'Person'),\n",
       " ('Wozniak', 'Person', 'Person'),\n",
       " ('Samson', 'Person', 'Person'),\n",
       " ('Ghazal', 'Person', 'Person'),\n",
       " ('9081-6208 Québec inc. (PDP Auto)', 'Company', 'Company'),\n",
       " ('Lakbir (Entretien Bahid)', 'Company', 'Company'),\n",
       " ('Air Spécialiste inc.', 'Company', 'Company'),\n",
       " ('Petit-Saguenay (Municipalité de)', 'Company', 'Company'),\n",
       " ('Boucher', 'Person', 'Person'),\n",
       " ('Nadeau Matériaux de construction inc.', 'Company', 'Company'),\n",
       " ('Bouvier', 'Person', 'Person'),\n",
       " ('Services Ricova inc. (Services Monde vert)', 'Company', 'Company'),\n",
       " ('Giraldeau Inter-Auto inc.', 'Company', 'Company'),\n",
       " ('Blais', 'Person', 'Person'),\n",
       " ('Langlois (Gestion HL)', 'Company', 'Company'),\n",
       " ('Dagenais', 'Person', 'Person'),\n",
       " ('Commission scolaire de la Seigneurie des Mille-<UNK>les',\n",
       "  'Company',\n",
       "  'Company'),\n",
       " ('Ratté', 'Person', 'Person'),\n",
       " ('Ferme Probec enr.', 'Company', 'Company'),\n",
       " ('Le Bouhris', 'Person', 'Person'),\n",
       " ('Agence du revenu du Québec', 'Company', 'Company'),\n",
       " ('Archambault', 'Person', 'Person'),\n",
       " ('Joyal', 'Person', 'Person'),\n",
       " ('Procureur général du Québec (Ministère des Transports)',\n",
       "  'Company',\n",
       "  'Company'),\n",
       " ('Lacroix', 'Person', 'Person'),\n",
       " ('Lefevre', 'Person', 'Person'),\n",
       " ('Poirier', 'Person', 'Person'),\n",
       " ('9287-8263 Québec inc.', 'Company', 'Company'),\n",
       " ('Lambert', 'Person', 'Person'),\n",
       " ('Condominiums Place Villeneuve', 'Company', 'Company'),\n",
       " ('Laturaze', 'Person', 'Person'),\n",
       " ('9186-8273 Québec inc. (Bel-Mar Express)', 'Company', 'Company'),\n",
       " ('Construction MMC inc.', 'Company', 'Company'),\n",
       " ('Passion Sport inc.', 'Company', 'Company'),\n",
       " (\"Dupuis Paquin Avocats et conseillers d'affaires inc.\",\n",
       "  'Company',\n",
       "  'Company'),\n",
       " ('Laforest', 'Person', 'Person'),\n",
       " ('Bossé', 'Person', 'Person'),\n",
       " ('Personnelle (La), assurances', 'Company', 'Company'),\n",
       " ('Bordua', 'Person', 'Person'),\n",
       " ('Chartray', 'Person', 'Person'),\n",
       " ('Donald', 'Person', 'Person'),\n",
       " ('Ryshpan', 'Person', 'Person'),\n",
       " ('Berky', 'Person', 'Person'),\n",
       " ('Hébert', 'Person', 'Person'),\n",
       " ('Marleau', 'Person', 'Person'),\n",
       " ('LMD Québec', 'Company', 'Company'),\n",
       " ('Climatisation et chauffage Thermaco inc.', 'Company', 'Company'),\n",
       " ('Amyot', 'Person', 'Person'),\n",
       " ('Rebelo', 'Person', 'Person'),\n",
       " ('9222-7156 Québec inc.', 'Company', 'Company'),\n",
       " ('VR Dépôt', 'Company', 'Company'),\n",
       " ('Vaillancourt-Vermette', 'Person', 'Person'),\n",
       " ('Pépin', 'Person', 'Person'),\n",
       " ('Riffaud (Kiwi Vibe)', 'Company', 'Company'),\n",
       " ('Noël', 'Company', 'Person'),\n",
       " ('Drummond Mobile Québec inc.', 'Company', 'Company'),\n",
       " ('9293-4579 Québec inc. (Option Évasions vacances)', 'Company', 'Company'),\n",
       " ('Do Sport 3R inc.', 'Company', 'Company'),\n",
       " ('Shotton', 'Person', 'Person'),\n",
       " ('Provigo Distribution inc. (Provigo Le Marché (Loblaws))',\n",
       "  'Company',\n",
       "  'Company'),\n",
       " ('Sénécal', 'Person', 'Person'),\n",
       " ('Xtraride', 'Person', 'Person'),\n",
       " ('Kaur', 'Person', 'Person'),\n",
       " ('Chapdelaine', 'Person', 'Person'),\n",
       " ('Canadian Tire Longueuil (Investissement Raymond Gagné ltée)',\n",
       "  'Company',\n",
       "  'Company'),\n",
       " ('Nasr', 'Person', 'Person'),\n",
       " ('LKQ Pintendre Autos', 'Company', 'Company'),\n",
       " ('Pouliot-Bertrand', 'Person', 'Person'),\n",
       " ('Roy', 'Person', 'Person'),\n",
       " ('9218-3805 Québec inc. (www.jaimemonvoyage.com)', 'Company', 'Company'),\n",
       " ('Keogh', 'Person', 'Person'),\n",
       " ('Fréchette', 'Person', 'Person'),\n",
       " ('Richard Seers Avocat inc.', 'Company', 'Company'),\n",
       " ('Bourgeois', 'Person', 'Person'),\n",
       " ('Mark', 'Person', 'Person'),\n",
       " ('Les Entreprises Sweetnfit inc. (Posture Pro)', 'Company', 'Company'),\n",
       " ('BBK Avocats inc.', 'Company', 'Company'),\n",
       " ('Bordeleau (CH Production inc.)', 'Company', 'Company'),\n",
       " ('Grandmont', 'Person', 'Person'),\n",
       " ('Joyal', 'Person', 'Person'),\n",
       " ('Chartrand', 'Person', 'Person'),\n",
       " ('Dumont', 'Person', 'Person'),\n",
       " ('Kabemba', 'Person', 'Person')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cpu()\n",
    "idx_to_char = {v:k for k, v in char_to_idx.items()}\n",
    "idx_to_tag = {v:k for k,v in tag_to_idx.items()}\n",
    "predictions = []\n",
    "for inputs, labels in dataloaders['test']:\n",
    "    seq = list(map(lambda seq : ''.join([idx_to_char[int(c)] for c in seq if 'PAD' not in idx_to_char[int(c)]]), inputs) )\n",
    "    pred = [idx_to_tag[int(l)] for l in torch.argmax(net(inputs),dim=1)]\n",
    "    label =[idx_to_tag[int(l)] for l in labels]\n",
    "    predictions.extend(zip(seq, pred, label))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('data-science': conda)",
   "language": "python",
   "name": "python37364bitdatascienceconda21efd4ba96a746aa869a1d54068eadd9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
